patterns:
- pattern: testing/*
  insights:
  - When signaling task completion, including specific test metrics (35 test cases,
    95% coverage, 122 total tests) provides QA with concrete verification targets.
    This allows QA to validate claims against actual test runs rather than relying
    on qualitative assessments.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - testing
  - process
  sample_count: 1
- pattern: architecture/*
  insights:
  - 'When implementing a new parser (e.g., Codex parser), following the exact structure
    of an existing parser (Claude parser) reduces errors and speeds implementation.
    Key elements to replicate: discovery method, session model extension, message
    extraction, tool usage extraction, and test structure. The dev signal explicitly
    referenced ''following the Claude parser pattern''.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - architecture
  - technical
  sample_count: 1
- pattern: code-review/*
  insights:
  - When QA reviews before dev completes work, signaling 'needs_revision' with specific
    missing requirements creates a clear handoff. The dev agent then implements to
    those requirements, and QA re-reviews. This pattern works better than QA waiting
    indefinitely, as it establishes clear expectations early.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - code-review
  - process
  sample_count: 1
- pattern: workflow/*
  insights:
  - 'Workflow completed successfully via quick iteration: dev signaled done (4 tests
    from QA gap), QA sent needs_revision with specific file:line reference, dev fixed
    in 2 minutes and re-signaled done, QA approved. Total revision cycle under 5 minutes.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow
  - process
  sample_count: 1
- pattern: reliability/*
  insights:
  - MCP 'Connection refused' errors can cause agents to fail silently without sending
    workflow signals. Monitor MCP server health and implement retry logic. Tmux session
    crashes combined with MCP issues lead to complete coordination failure even when
    code work is successful.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - reliability
  - technical
  sample_count: 1
- pattern: workflow-coordination/*
  insights:
  - When agents fail to register with the workflow within a timeout period, the orchestrator
    should detect this early and log clear error messages. The root cause of this
    failure was agents never registering - checking tmux pane status after spawn could
    provide visibility into spawn failures.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-coordination
  - process
  sample_count: 1
- pattern: implementation/*
  insights:
  - 'The dev agent''s done signal explicitly listed all implemented components: discover_sessions,
    parse_session_file, analyze returning AnalysisResult, and ObsidianFormatter. This
    detailed signaling helps with workflow recovery and audit trails when issues occur.'
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - implementation
  - process
  sample_count: 1
- pattern: debugging/*
  insights:
  - When using git worktrees for parallel development, pytest can pick up wrong module
    from another worktree's sys.path. QA agent discovered that explicit PYTHONPATH=src
    or editable install is required to ensure tests use the correct worktree's code.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - debugging
  - technical
  sample_count: 1
- pattern: python/*
  insights:
  - Structure pyproject.toml with core dependencies in [project.dependencies] and
    testing/linting tools in [project.optional-dependencies.dev]. Use 'uv run --extra
    dev pytest' for CI/QA verification. Configure tool settings (pytest, mypy, ruff)
    in the same file.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - python
  - technical
  sample_count: 1
- pattern: agent-lifecycle/*
  insights:
  - Workflows running over 10 minutes need active heartbeat monitoring to detect agent
    death before the full timeout. The dev agent died without signaling, causing the
    workflow to fail silently. Implementing periodic heartbeat checks (every 60-120
    seconds) would allow earlier detection and potential agent restart.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - agent-lifecycle
  - process
  sample_count: 1
- pattern: task-recovery/*
  insights:
  - When an agent dies mid-task, all progress is lost if no intermediate commits exist.
    Agents should checkpoint progress by committing partial work frequently (every
    significant change), enabling workflow resumption from the last checkpoint rather
    than restarting from scratch.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - task-recovery
  - process
  sample_count: 1
- pattern: validation/*
  insights:
  - The improvement logs indicate adding a 'validate' state before 'engineering' helps
    isolate environment/setup issues from implementation issues. Running a single-agent
    validation step first proves the execution environment works before spawning multiple
    agents, reducing complex failure modes.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - validation
  - process
  sample_count: 1
