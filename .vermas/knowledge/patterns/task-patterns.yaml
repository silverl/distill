patterns:
- pattern: architecture/*
  insights:
  - "The improvement YAML captured that bundling multiple KPIs (weekly digests + test\
    \ coverage) into a single task caused attribution failures \u2014 when the task\
    \ partially succeeds, it's unclear which KPI was addressed. The recommendation\
    \ to isolate one KPI per task, combined with mandatory root-cause analysis before\
    \ retrying failed tasks, was captured as a prompt-level improvement with measured\
    \ 45% prior success rate."
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - architecture
  - process
  sample_count: 1
- pattern: git-workflow/*
  insights:
  - "Code written in git worktrees that is never committed exists only as working\
    \ directory changes. When the workflow fails, the code is stranded \u2014 not\
    \ on main, not on a branch, just in the worktree's working directory. Recovery\
    \ requires manual intervention (selective file checkout or copy from worktree\
    \ path). This project has accumulated ~5,000+ LOC of stranded code across worktrees\
    \ and branches from 12+ such failures."
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - git-workflow
  - technical
  sample_count: 1
- pattern: verification/*
  insights:
  - 'The workflow passed all agent-level checks (tests pass, code committed) but failed
    at the delivery level because verification happened on the worktree branch, not
    on main. Pre-completion verification must include: (1) source files exist on main,
    (2) the main commit itself contains src/tests diffs, not just the branch. Without
    this, artifact-only commits on main pass all gates.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - verification
  - process
  sample_count: 1
- pattern: testing/*
  insights:
  - Despite the watcher agent running in a mismatched context (cycle 1 planning meeting),
    its 159-line trace provided valuable forensic data for understanding what actually
    happened during the workflow. The watcher's trace showed it was exploring the
    codebase and measuring KPIs from a prior cycle, confirming the session reuse issue.
    Preserving agent traces even for failed workflows is essential for debugging.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - testing
  - technical
  sample_count: 1
- pattern: code-recovery/*
  insights:
  - When integrating components developed in git worktrees, first verify and commit
    the code to main before wiring them into the core system. This workflow successfully
    recovered 1,140 lines of Codex parser code and 2,030 lines of VerMAS parser code
    that existed in worktrees but were never committed. The recovery step (commits
    d9e3b74, becde1e) preceded the integration step (commit 9d038df).
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - code-recovery
  - process
  sample_count: 1
- pattern: infrastructure/*
  insights:
  - 'The error message ''agents died. Dead roles: [watcher, dev, qa]'' provides no
    information about why the tmux session ended (timeout, user action, resource exhaustion,
    or system restart). Adding diagnostic logging before session teardown would enable
    root cause analysis.'
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - infrastructure
  - technical
  sample_count: 1
- pattern: error-handling/*
  insights:
  - The 'agents died' error should first check if the workflow has already completed
    via signals. In this case, all three roles had signaled success within 3 minutes
    (14:04-14:06) before the QA agent died. A pre-failure signal check would have
    correctly identified this as a successful completion with agent cleanup issue
    rather than a failed workflow.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - error-handling
  - technical
  sample_count: 1
- pattern: compatibility/*
  insights:
  - When two parts of a system use similar but incompatible data models, add compatibility
    properties to the newer model rather than changing all consumers. The BaseSession
    in parsers/models.py gained properties like 'id' (aliasing session_id), 'start_time'
    (aliasing timestamp), and 'tools_used' (converting tool_calls) to maintain compatibility
    with models/__init__.py:BaseSession consumers.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - compatibility
  - technical
  sample_count: 1
- pattern: workflow-reliability/*
  insights:
  - When an agent sends its final signal (done/approved/complete) and then terminates
    before the orchestrator acknowledges, the framework reports 'agents died' despite
    successful completion. The workflow recorded three successful signals (dev done
    at 14:04, QA approved at 14:06, watcher complete at 14:06) yet reported failure.
    Orchestrators should check for existing completion signals before declaring failure.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-reliability
  - technical
  sample_count: 1
- pattern: code-review/*
  insights:
  - "The main completion commit (fe356532) contains only trace logs, knowledge YAML\
    \ updates, and worktree pointer changes \u2014 zero lines in src/ or tests/. This\
    \ is the 12th occurrence of this pattern in the project. A pre-merge gate checking\
    \ `git diff --stat -- src/ tests/` would catch this every time. The branch commit\
    \ (4f381c80) similarly contained only generated insight markdown, not source code."
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - code-review
  - process
  sample_count: 1
- pattern: dependencies/*
  insights:
  - 'Task required Click dependency but dev initially signaled done without it. QA
    caught this in first review cycle. Pattern: run ''uv sync'' or equivalent and
    verify imports work before claiming task completion. Dependencies are a common
    oversight in verification tasks.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - dependencies
  - technical
  sample_count: 1
- pattern: workflow-resilience/*
  insights:
  - When tmux sessions terminate unexpectedly, agents die without opportunity to save
    state or signal failure. This creates opaque failures reported as 'agents died'
    without diagnostic information. Long-running tasks are particularly vulnerable
    to this infrastructure failure mode.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-resilience
  - process
  sample_count: 1
- pattern: task-decomposition/*
  insights:
  - 'The task had exactly three acceptance criteria: (1) add --output argument with
    default, (2) create directory if missing, (3) print confirmation message. This
    atomic scope allowed dev to complete implementation quickly and QA to verify each
    criterion explicitly. Following the pattern from cycle-5, small focused tasks
    outperform monolithic implementations.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - task-decomposition
  - process
  sample_count: 1
- pattern: failure-recovery/*
  insights:
  - When cycle-4 'implement-cli-skeleton' failed, the system had already evolved a
    decomposition plan. Cycle-5 'add-analyze-subcommand-stub' succeeded with 186 tests
    passing. This validates that incremental task breakdown is an effective recovery
    strategy after infrastructure or scope failures.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - failure-recovery
  - process
  sample_count: 1
- pattern: performance/*
  insights:
  - When parsing file-discovery-based sources (like VerMAS scanning .vermas/ directories),
    implement a _parsed_dirs cache to track already-processed directories. Without
    this, scanning multiple files from the same source creates duplicate sessions
    in aggregated results. Add reset_cache() function for test isolation.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - performance
  - technical
  sample_count: 1
- pattern: debugging/*
  insights:
  - The dev agent investigated the existing implementation before writing a fix and
    discovered the logic was already correct (Path(cwd).name). Instead of blindly
    rewriting code, the agent confirmed the task only needed test coverage for specific
    real-world paths. This saved time and avoided introducing regressions from unnecessary
    code changes.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - debugging
  - technical
  sample_count: 1
- pattern: integration/*
  insights:
  - When adding new session sources to a discovery system, update SESSION_PATTERNS
    to include the new directory patterns (.claude/, .codex/, .vermas/) AND update
    parse_session_file() dispatch logic to route to the correct parser based on file
    path context. QA should explicitly verify both discovery and parsing for each
    new source.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - integration
  - technical
  sample_count: 1
- pattern: task-planning/*
  insights:
  - This workflow attempted 'implement-cli-skeleton' when cli.py already exists in
    git with multiple prior commits. Task backlog systems must query git (git ls-files
    --error-unmatch <deliverable>) before spawning agent workflows. Tasks targeting
    existing files should be auto-converted to 'enhance' or 'fix' tasks, or auto-closed
    entirely.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - task-planning
  - process
  sample_count: 1
- pattern: workflow-lifecycle/*
  insights:
  - "When agents complete their work and signal done/approved/complete but their tmux\
    \ sessions terminate before the state machine can cleanly transition, the workflow\
    \ is marked as 'failure' with 'agents died' even though all deliverables were\
    \ produced. The state machine should check signal state before declaring failure\
    \ on agent death \u2014 if all required signals (done, approved, complete) are\
    \ present, the workflow succeeded regardless of agent process state."
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-lifecycle
  - process
  sample_count: 1
- pattern: specification-compliance/*
  insights:
  - Dev initially implemented with typer/rich/pydantic when spec explicitly required
    click>=8.0. Over-building creates drift from requirements and extra rework during
    QA. Always start with the minimal spec (dependencies explicitly listed in task
    definition) and resist adding conveniences not specified in requirements.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - specification-compliance
  - process
  sample_count: 1
- pattern: task-validation/*
  insights:
  - The obsidian formatter was marked as status:done in the task backlog (implement-obsidian-formatter.md)
    yet a new workflow attempted to add it. Task orchestration should cross-reference
    backlog status and git file existence before spawning workflows. The existing
    file tracking showed obsidian.py committed in multiple prior commits.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - task-validation
  - process
  sample_count: 1
- pattern: error-diagnostics/*
  insights:
  - 'The error ''agents died. Dead roles: [watcher, dev, qa]'' provides no information
    about why the tmux session ended (timeout, user action, resource exhaustion, or
    crash). Adding pre-termination hooks or periodic state snapshots would enable
    root cause analysis and distinguish recoverable from fatal failures.'
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - error-diagnostics
  - technical
  sample_count: 1
- pattern: task-backlog/*
  insights:
  - Tasks targeting files that already exist in git should be automatically converted
    to 'enhance' or 'fix' variants, or auto-closed with explanation. This prevents
    wasted compute on obsolete work and aligns the backlog with actual codebase state.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - task-backlog
  - process
  sample_count: 1
- pattern: workflow-coordination/*
  insights:
  - Running three fix tasks in parallel (narrative, project-names, coverage) resulted
    in all three producing artifact-only commits. When tasks run in parallel, there
    is no sequential checkpoint to catch the pattern early. A serial ordering with
    verification after each task would have caught the first artifact-only commit
    and prevented the subsequent two from repeating the same failure mode.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-coordination
  - process
  sample_count: 1
- pattern: cli-development/*
  insights:
  - 'When a task requires importing modules for future use but linters flag them as
    unused, create a registry pattern (like PARSERS = {''claude'': ClaudeParser, ...})
    that references the imports. This documents the intended mapping while satisfying
    static analysis.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - cli-development
  - technical
  sample_count: 1
- pattern: workflow/*
  insights:
  - The QA agent correctly identified empty delivery with a needs_revision signal,
    but the workflow orchestrator still classified the outcome as 'success'. This
    indicates the success/failure classification is based on workflow completion (all
    agents finished) rather than deliverable verification (code on main with src changes).
    Workflow orchestrators must gate success classification on QA approval, not just
    completion.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow
  - process
  sample_count: 1
- pattern: workflow-signals/*
  insights:
  - The pre-signal-check.sh script (fixed in 33f3b78 to check HEAD~1..HEAD) still
    cannot detect when a completion commit omits source changes that exist on the
    task branch. It only checks if the latest commit has source diffs vs main, not
    whether the task branch's source changes were included. A new check comparing
    'git diff main..task-branch -- src/ tests/' would catch this.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-signals
  - technical
  sample_count: 1
- pattern: discovery/*
  insights:
  - Before implementing any task, agents should first check if the deliverable already
    exists. In this workflow, the dev agent correctly identified that the directory
    structure was already present and reported verification instead of attempting
    recreation. This avoids duplicate work and maintains idempotency.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - discovery
  - process
  sample_count: 1
- pattern: recovery/*
  insights:
  - When code exists in worktrees or branches but was never merged to main, use selective
    file recovery (git checkout or file copy) rather than reimplementing from scratch.
    This workflow recovered 716 LOC of tests from an untracked worktree in one commit,
    avoiding the multi-cycle reimplementation attempts that had previously failed.
    Recovery preserves battle-tested code that was already written and reviewed.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - recovery
  - process
  sample_count: 1
- pattern: observability/*
  insights:
  - 'Workflow failures can occur at multiple levels: code implementation, test execution,
    commit/merge operations, or orchestration (agent registration, signal delivery).
    The root cause analysis identified MCP connection refused errors and missing agent
    registrations as orchestration issues, not code issues.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - observability
  - process
  sample_count: 1
- pattern: resilience/*
  insights:
  - When the dev agent's session crashed mid-implementation, the watcher detected
    it and signaled 'blocked'. The dev agent restarted, found partial work already
    on disk, and completed implementation within minutes. Crash recovery works when
    agents persist work to files incrementally rather than holding everything in memory
    until final commit.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - resilience
  - process
  sample_count: 1
- pattern: git/*
  insights:
  - Always run explicit `git add` for deliverable files and verify with `git ls-files
    --error-unmatch` before signaling done. The common failure mode is creating files
    in the working directory without committing them, which breaks the 'done means
    committed to main' principle.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - git
  - technical
  sample_count: 1
- pattern: process/*
  insights:
  - This workflow committed code directly to main (c29c088c) rather than creating
    a feature branch and merging. This is the 11th consecutive successful direct-to-main
    delivery in this project, compared to 0/11 branch merges succeeding. For small,
    focused wiring tasks especially, direct-to-main eliminates the merge-drops-source
    failure mode entirely.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - process
  - process
  sample_count: 1
- pattern: workflow-management/*
  insights:
  - This workflow completed successfully (QA approved, commit made) but was reported
    as 'failure' due to 'agents died' when tmux sessions ended. Workflow success should
    be determined by signal state (complete/approved) rather than agent session liveness.
    Final state showed watcher reporting successful completion.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-management
  - process
  sample_count: 1
- pattern: qa-feedback/*
  insights:
  - "QA agent (Codex) provided two rounds of actionable feedback citing exact missing\
    \ requirements: core.py pipeline wiring, formatter sections (Major Milestones,\
    \ Key Decisions, Related Sessions), and per-project coverage enforcement. This\
    \ specificity enabled dev to address all issues without clarification rounds.\
    \ The full cycle (initial review \u2192 revision \u2192 re-review \u2192 revision\
    \ \u2192 approval) completed in under 15 minutes."
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - qa-feedback
  - process
  sample_count: 1
- pattern: workflow-efficiency/*
  insights:
  - The dev-QA interaction used workflow signals (done, needs_revision, done, needs_revision,
    done, approved) without synchronous meetings, completing the full implementation-review-revision
    cycle in 669 seconds. The signal messages contained enough context (commit hashes,
    specific issues, file paths) to eliminate the need for back-and-forth clarification.
    This async pattern is more efficient than meeting-based coordination for well-defined
    tasks.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-efficiency
  - process
  sample_count: 1
- pattern: gate-0-validation/*
  insights:
  - The task 'add-obsidian-formatter' targeted src/session_insights/formatters/obsidian.py
    which already exists as a 10KB file with 17KB of compiled bytecode. Running 'git
    ls-files --error-unmatch src/session_insights/formatters/obsidian.py' before workflow
    launch would have detected this immediately. This is the same Gate 0 failure pattern
    observed in cycles 5-12.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - gate-0-validation
  - process
  sample_count: 1
- pattern: agent-reliability/*
  insights:
  - QA agent signaled 'approved' at 14:56:11, then dev signaled 'done' at 14:57:22,
    watcher signaled 'complete' at 14:57:47. Yet workflow failed because QA agent
    died afterward. The orchestrator should treat post-completion agent death differently
    than mid-task failure, preserving the success state.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - agent-reliability
  - process
  sample_count: 1
- pattern: documentation/*
  insights:
  - The diagnostic report included clear verification steps (test import without dev
    deps, test CLI execution, run test suite) that allow QA or future developers to
    confirm fixes work. This makes the diagnostic actionable rather than just informational.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - documentation
  - technical
  sample_count: 1
- pattern: pydantic/*
  insights:
  - When a Pydantic subclass needs different calculation logic than its base class
    property, add an explicit property override in the subclass. VermasSession.duration_minutes
    was added to override BaseSession's calculation that returned 0/Unknown for sessions
    with different time field semantics.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - pydantic
  - technical
  sample_count: 1
- pattern: validation/*
  insights:
  - 'Effective CLI validation verifies: (1) entry point executes without import errors,
    (2) parser produces expected session counts from real data, (3) output format
    has valid structure (YAML frontmatter, markdown), (4) aggregations calculate correctly
    (durations, counts). This 4-point check validated parse_success_rate and obsidian_compatibility
    KPIs.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - validation
  - process
  sample_count: 1
- pattern: cli/*
  insights:
  - The sessions command outputs structured JSON (session_count, total_messages, date_range,
    sources) rather than formatted text. This enables piping output to other tools
    (jq, scripts) and makes the CLI composable. For discovery/listing commands, JSON
    is preferable to human-readable output.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - cli
  - technical
  sample_count: 1
- pattern: task-design/*
  insights:
  - 'The task definition was clear and well-scoped: build an automated narrative quality
    scorer with specific rejection criteria (XML tags, short summaries, literal commands,
    file paths), fix narrative generation, and add tests targeting 80% quality. The
    dev agent made meaningful progress (199 LOC scorer + 57 LOC narrative fixes) but
    failed to complete the commit-test-signal cycle. Well-defined tasks still fail
    when execution infrastructure (worktree commits, workflow timeouts) is unreliable.'
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - task-design
  - process
  sample_count: 1
- pattern: gate-checking/*
  insights:
  - Before starting an implementation task, Gate 0 must confirm the deliverable does
    not already exist in the codebase. In this workflow, the 'implement-analyze-command'
    task failed because the analyze command already existed from cycle 16 (commit
    5a0f625). A simple `git ls-files --error-unmatch` check or code search would have
    caught this before any work began.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - gate-checking
  - process
  sample_count: 1
- pattern: commits/*
  insights:
  - A commit that modifies only workflow artifacts (.yaml, .md, __pycache__) without
    changing any source code or test files is an artifact-only commit. Commit d2194b7
    claimed to 'Implement analyze CLI command with full pipeline' but contained 0
    src/test changes. Post-execution verification must diff src/ and tests/ directories
    against the parent commit, not against main, to catch this pattern.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - commits
  - process
  sample_count: 1
- pattern: action-items/*
  insights:
  - Action items act-2d5f5e36 (fix pre-signal-check.sh) and act-4b987d19 (create pre-task-check.sh)
    would have prevented this failure but remained unexecuted for 3+ cycles. The systemic
    issue is that task planners create new tasks instead of pulling from the action
    item backlog, causing the same failure modes to recur. Future workflows should
    check pending action items before planning new work.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - action-items
  - process
  sample_count: 1
- pattern: workflow-design/*
  insights:
  - The workflow was recorded as 'success' with 314s duration, but QA signaled needs_revision
    because the primary deliverable was missing. This indicates the workflow completion
    signal was based on the dev agent finishing execution rather than QA approval.
    Workflow success should require QA approval signal, not just dev completion, to
    prevent false-positive success reporting.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-design
  - process
  sample_count: 1
- pattern: deployment/*
  insights:
  - 'This is the 12th occurrence of the merge-drops-source pattern where a branch
    contains real code (+359 LOC across 6 files) but the merge commit to main contains
    only artifact/metadata changes. The direct-to-main mandate (10/10 success rate)
    was already established but was not followed in this workflow. Worktree-based
    workflows continue to fail at the merge step. The consistent mitigation is: never
    merge branches, always commit directly to main or use selective file checkout
    (git checkout branch -- file).'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - deployment
  - process
  sample_count: 1
- pattern: workflow-automation/*
  insights:
  - 'Three action items from prior reviews (act-8c5932eb: .gitignore cleanup, act-2d5f5e36:
    pre-signal-check.sh fix, coverage fix) were finally executed as direct commits
    (8269907, 33f3b78, eb44c93) immediately after the M2e-C3 review. This broke the
    pattern of action items never being executed by treating them as standalone fixes
    rather than routing through the full workflow cycle.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-automation
  - process
  sample_count: 1
- pattern: implementation/*
  insights:
  - 'When generating narratives from incomplete data, use a fallback chain: first
    try cleaned summary, then task_description, then synthesize from structured metadata
    (tool names with counts, session duration, tags), and finally fall back to project
    name. Each level produces progressively less specific but still useful content,
    ensuring no narrative is ever empty or contains raw artifacts.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - implementation
  - technical
  sample_count: 1
- pattern: refactoring/*
  insights:
  - 'The successful approach was: (1) move shared type definitions from the specialized
    module (vermas.py) to the base module (models.py), (2) extend BaseSession with
    new fields using Optional/default-empty-list patterns, (3) update the specialized
    class to inherit rather than redefine, (4) add model_post_init() to auto-derive
    computed fields. This 4-step pattern achieved +141/-77 LOC (net +64) with zero
    test regressions across 218 tests.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - refactoring
  - technical
  sample_count: 1
- pattern: code-delivery/*
  insights:
  - "Three parallel fix tasks (fix-narrative-generation, fix-project-name-derivation,\
    \ boost-test-coverage-to-90) all produced commits with zero changes to src/ or\
    \ tests/ directories \u2014 only workflow metadata. This is the 12th-14th occurrence\
    \ of artifact-only delivery in this project. The pattern persists even with pre-signal-check.sh\
    \ in place, suggesting the check is not being enforced during multi-agent parallel\
    \ task execution."
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - code-delivery
  - process
  sample_count: 1
- pattern: qa-workflow/*
  insights:
  - 'QA agent (Codex) provided two rounds of precise, actionable feedback: Round 1
    identified that measurers should run CLI and parse generated files (not format
    sessions directly) and flagged timestamp field mismatches. Round 2 caught a spec
    mismatch (task_description checking always-present marker instead of actual content)
    and environment issues. Dev fixed both rounds quickly (9 minutes and 4 minutes
    respectively). The specificity of QA feedback (exact field names, exact test commands,
    exact error descriptions) enabled rapid turnaround.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - qa-workflow
  - process
  sample_count: 1
- pattern: quality-assurance/*
  insights:
  - The QA agent correctly identified that KPI_BASELINE.md was missing and that the
    branch had no meaningful diffs vs main for the required deliverable. This demonstrates
    the value of QA agents performing explicit deliverable-existence checks rather
    than just reviewing what was committed. The QA signal 'branch has no diffs vs
    main and KPI_BASELINE.md is missing' was precise and actionable.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - quality-assurance
  - process
  sample_count: 1
- pattern: code-quality/*
  insights:
  - 'The dev created a well-structured derive_project_name() utility in models.py
    that handles worktree paths (.worktrees/branch -> parent project), git worktree
    paths (.git/worktrees/name), Claude-encoded project dirs (-Users-name-GitHub-proj),
    root paths, and trailing slashes. This consolidated duplicate derivation logic
    from claude.py and codex.py into one tested function with 20+ unit tests. This
    is a strong pattern for any path-parsing utility: enumerate edge cases explicitly,
    centralize into one function, test each case independently.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - code-quality
  - technical
  sample_count: 1
- pattern: workflow-orchestration/*
  insights:
  - Despite the established direct-to-main mandate (8/8 success rate vs 0/9 for branch
    merges), the worktree-based workflow inherently creates a branch for the dev agent
    to commit to. The workflow infrastructure itself creates the conditions for the
    merge-drops-source failure mode. Workflow DSL needs to either commit directly
    to main or include an explicit merge-to-main step before signaling complete.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-orchestration
  - process
  sample_count: 1
- pattern: delivery/*
  insights:
  - "When agents work in git worktrees, their commits land on task branches rather\
    \ than main. This is the 'uncommitted-completion' failure mode \u2014 the work\
    \ exists but not where it needs to be. The dev agent committed 716 LOC of tests\
    \ to the worktree branch (c68657b) which required a separate recovery commit (636affe)\
    \ to get onto main. Agents working in worktrees must be explicitly instructed\
    \ to commit directly to main or the workflow should include a merge-to-main step."
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - delivery
  - process
  sample_count: 1
- pattern: environment/*
  insights:
  - QA agent's initial pytest run failed because dev dependencies weren't installed
    in QA's environment. The QA agent had to install deps before running tests. Workflows
    should ensure all agents share the same virtual environment or include environment
    setup as a prerequisite step, especially when QA needs to run the same test suite
    the dev agent created.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - environment
  - process
  sample_count: 1
- pattern: monitoring/*
  insights:
  - 'The watcher agent issued two signals: first ''blocked'' when it detected the
    dev session ended mid-implementation (correctly diagnosing partial changes on
    disk but no commit), then ''progress'' when it observed the dev recovering and
    making incremental progress. The watcher''s file-level change tracking (obsidian.py
    +7, narrative.py +9, test_narrative.py +110) provided precise visibility into
    implementation progress without interfering with the dev agent''s work.'
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - monitoring
  - process
  sample_count: 1
- pattern: workflow-execution/*
  insights:
  - A 213-second (3.5 minute) workflow duration for a task requiring code implementation,
    testing, and QA review is insufficient. The dev agent likely ran out of time or
    encountered an error before completing the commit cycle. Successful implementation
    tasks in this project typically require 10-30 minutes. Workflow orchestrators
    should set minimum duration thresholds based on task complexity.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - workflow-execution
  - process
  sample_count: 1
- pattern: agent-coordination/*
  insights:
  - Agents must commit code to the branch before signaling 'done' or before the workflow
    state machine transitions. A pre-signal verification check (pre-signal-check.sh)
    exists in this project but the agent either didn't run it or the workflow failed
    before reaching that stage. Enforcing commit-before-signal at the infrastructure
    level (not just agent-level) would prevent code loss from both timeout and crash
    scenarios.
  revision_rate: null
  success_rate: 0.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - agent-coordination
  - process
  sample_count: 1
- pattern: task-execution/*
  insights:
  - "The dev agent committed 43 files with 1,584 insertions but none of them were\
    \ the requested deliverable (KPI_BASELINE.md). High output volume (generated insight\
    \ files from running the pipeline) created the appearance of completion while\
    \ the actual task requirement \u2014 recording specific KPI measurements in a\
    \ structured file \u2014 was entirely missed. Agents should verify deliverable\
    \ existence before signaling done."
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - task-execution
  - process
  sample_count: 1
- pattern: requirements/*
  insights:
  - "The task required two distinct steps: (1) running the analyze pipeline and (2)\
    \ recording measurements in KPI_BASELINE.md. The dev agent completed step 1 (evidenced\
    \ by 40+ generated files) but skipped step 2 entirely. When tasks involve both\
    \ running a tool AND recording its output, the recording step must be treated\
    \ as a separate, explicit checklist item \u2014 not assumed to happen automatically."
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - requirements
  - process
  sample_count: 1
- pattern: commit-hygiene/*
  insights:
  - The commit included 43 files of generated pipeline output (session insights, project
    notes, index updates) which made the commit appear substantial. However, these
    were side-effects of running the pipeline, not the requested deliverable. Committing
    large volumes of generated output alongside task work makes it harder to verify
    that specific deliverables are present. Pre-commit checks should verify named
    deliverables exist before allowing the commit.
  revision_rate: null
  success_rate: 1.0
  avg_duration: null
  recommended_workflow: null
  tags:
  - commit-hygiene
  - technical
  sample_count: 1
